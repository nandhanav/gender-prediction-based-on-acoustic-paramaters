import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
df = pd.read_csv('voice.csv')
df.head(3168)
df.isnull().sum()
df.isnull()
df.duplicated()
df['label'].value_counts()
label=df.label.value_counts().index
count=df.label.value_counts().values
plt.title('gender Distribution')
plt.pie(count,labels=label)
df.dtypes
x = df.iloc[:,:-1]
y = df.iloc[:,-1]
print(type(x))
print(type(y))
print(x.shape)
print(y.shape)
x.head(3168)
y.head(3168)
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.20)
print(x_train.shape)
print(x_test.shape)
print(y_train.shape)
print(y_test.shape)
from sklearn.tree import DecisionTreeClassifier
m1 = DecisionTreeClassifier(criterion = 'gini',max_depth=20,min_samples_split = 2534)
m1.fit(x_train,y_train)
print('training score',m1.score(x_train,y_train))
print('testing score',m1.score(x_test,y_test))
#accuracy value
ypred_m1 = m1.predict(x_test)
print(ypred_m1)
from sklearn.metrics import confusion_matrix,classification_report
cm_m1 = confusion_matrix(y_test,ypred_m1)
print(cm_m1)
print(classification_report(y_test,ypred_m1))
from sklearn.ensemble import RandomForestClassifier
m2 = RandomForestClassifier(n_estimators = 150, criterion = 'entropy',max_depth=20,min_samples_split = 2534)
m2.fit(x_train,y_train)
print('training score',m2.score(x_train,y_train))
print('testing score',m2.score(x_test,y_test))
ypred_m2 = m1.predict(x_test)
print(ypred_m2)
cm_m2 = confusion_matrix(y_test,ypred_m2)
print(cm_m2)
print(classification_report(y_test,ypred_m2))
from sklearn.neighbors import KNeighborsClassifier
m3 = KNeighborsClassifier(n_neighbors=20)
m3.fit(x_train,y_train)
print('training score',m3.score(x_train,y_train))
print('testing score',m3.score(x_test,y_test))
ypred_m3 = m3.predict(x_test)
print(ypred_m3)
cm_m3 = confusion_matrix(y_test,ypred_m3)
print(cm_m3)
print(classification_report(y_test,ypred_m3))
from sklearn.svm import SVC
m5 = SVC(kernel = 'linear',C=1)
m5.fit(x_train,y_train)
print('training score',m5.score(x_train,y_train))
print('testing score',m5.score(x_test,y_test))
ypred_m5 = m5.predict(x_test)
print(ypred_m5)
cm_m5 = confusion_matrix(y_test,ypred_m5)
print(cm_m5)
print(classification_report(y_test,ypred_m5))
m6 = SVC(kernel='rbf',C=10,gamma=10)
m6.fit(x_train,y_train)
print('Training Score',m6.score(x_train,y_train))
print('Testing Score',m6.score(x_test,y_test))
ypred_m6 = m6.predict(x_test)
print(ypred_m6)
cm_m6 = confusion_matrix(y_test,ypred_m6)
print(cm_m6)
print(classification_report(y_test,ypred_m6,zero_division=0))
m7 = SVC(kernel='poly',C=10,degree=4)
m7.fit(x_train,y_train)
print('Training Score',m7.score(x_train,y_train))
print('Testing Score',m7.score(x_test,y_test))
ypred_m7 = m7.predict(x_test)
print(ypred_m7)
cm_m7 = confusion_matrix(y_test,ypred_m7)
print(cm_m7)
print(classification_report(y_test,ypred_m7,zero_division=0))
from sklearn.linear_model import LogisticRegression
m4 = LogisticRegression(solver = 'liblinear')
m4.fit(x_train,y_train)
print('training score',m4.score(x_train,y_train))
print('testing score',m4.score(x_test,y_test))
ypred_m4 = m4.predict(x_test)
print(ypred_m4)
cm_m4 = confusion_matrix(y_test,ypred_m4)
print(cm_m4)
print(classification_report(y_test,ypred_m4))
